{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umeshrawat/AI_Math_Vedas/blob/master/NLP1_Word_and_Sentence_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki6jcwCjGwk1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo4S8f58Gwk9"
      },
      "source": [
        "# Word Embeddings\n",
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYyDkHMSGwk_"
      },
      "outputs": [],
      "source": [
        "# First, you'll need to install gensim\n",
        "# !pip install gensim\n",
        "\n",
        "# Import the necessary modules\n",
        "\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0FCHyZ0GwlB",
        "outputId": "eef5a449-fd79-43c3-d358-751fc96252e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
          ]
        }
      ],
      "source": [
        "print(common_texts) #Sample Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obAnQvieGwlE"
      },
      "source": [
        " Word2vec accepts several parameters that affect both training speed and quality.\n",
        "\n",
        "One of them is for pruning the internal dictionary. Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. In addition, there’s not enough data to make any meaningful training on those words, so it’s best to ignore them:\n",
        "\n",
        "`model = Word2Vec(sentences, min_count=10)  # default value is 5`\n",
        "\n",
        "A reasonable value for min_count is between 0-100, depending on the size of your dataset.\n",
        "\n",
        "Another parameter is the size of the NN layers, which correspond to the “degrees” of freedom the training algorithm has:\n",
        "\n",
        "`model = Word2Vec(sentences, vector_size=200)  # default value is 100`\n",
        "\n",
        "Bigger size values require more training data, but can lead to better (more accurate) models. Reasonable values are in the tens to hundreds."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other hyper-parameters:\n",
        "\n",
        "*   size: window=window_size for capturing context for target word\n",
        "\n",
        "*   sample: The threshold for configuring which higher-frequency words are randomly down sampled, useful range is (0, 1e-5)\n",
        "\n",
        "*   workers: Use these many worker threads to train the model (faster training with multicore machines)\n",
        "\n",
        "*   sg: Training algorithm: skip-gram if sg=1, otherwise CBOW.\n",
        "\n",
        "*   iter: Number of iterations (epochs) over the corpus.\n"
      ],
      "metadata": {
        "id": "eHJa7t_dVlNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enTdB5hPGwlH"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences=common_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
        "#Here, vector_size = 10 denotes the length of embedding\n",
        "model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiL5GEqaGwlJ"
      },
      "source": [
        "If you save the model you can continue training it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVn5-eMTGwlK"
      },
      "outputs": [],
      "source": [
        "# load the saved model\n",
        "model = Word2Vec.load(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcwKsP0OGwlM"
      },
      "source": [
        "The trained word vectors are stored in a KeyedVectors instance, as model.wv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ-S-El4GwlO",
        "outputId": "6f99fced-ff2e-494e-807f-c91eb5ff39ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00410223 -0.08368949 -0.05600012  0.07104538  0.0335254   0.0722567\n",
            "  0.06800248  0.07530741 -0.03789154 -0.00561806]\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "# Get the embeddings for the word 'human'\n",
        "embedding = model.wv['human']\n",
        "\n",
        "print(embedding)\n",
        "print(len(embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zWtQqtrGwlP",
        "outputId": "84b56aab-4ac0-4d39-fdae-ee9e0aea676c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('graph', 0.3586882948875427), ('system', 0.22743132710456848), ('time', 0.1153423935174942)]\n"
          ]
        }
      ],
      "source": [
        "# Get the most similar words (having the most similar embeddings)\n",
        "similar_words = model.wv.most_similar('human',topn = 3) #topn denotes the top 3 similar words\n",
        "print(similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrllmXJqGwlR"
      },
      "outputs": [],
      "source": [
        "# Store just the words + their trained embeddings.\n",
        "word_vectors = model.wv\n",
        "word_vectors.save(\"word2vec.wordvectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFj9xhGgGwlS",
        "outputId": "afa5a92b-ad60-428a-9037-8690f345faee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0163195 ,  0.00189972,  0.03474648,  0.00217841,  0.09621626,\n",
              "        0.05062076, -0.08919986, -0.0704361 ,  0.00901718,  0.06394394],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Load back with memory-mapping = read-only, shared across processes.\n",
        "from gensim.models import KeyedVectors\n",
        "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
        "wv['computer']  # Get numpy vector embedding for 'computer'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hme83l4GwlT"
      },
      "source": [
        "### Refer to the link below for more details:\n",
        "https://radimrehurek.com/gensim/models/word2vec.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM6M_oYAGwlU"
      },
      "source": [
        "# Gensim comes with several already pre-trained models, in the Gensim-data repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEvTubVQGwlV",
        "outputId": "af785698-8770-4529-fcc0-f64c7bd78a0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "# Show all available models in gensim-data\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gl5eMeCGwlV",
        "outputId": "568882d2-f4c8-4b5b-e294-ab9b3be9fd2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.KeyedVectors at 0x7d8a02e6b700>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Download the \"glove-twitter-25\" embeddings\n",
        "# Pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased.\n",
        "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
        "glove_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcG_GXoUGwlX",
        "outputId": "3bd36b29-79ca-40e1-a4a9-0500520ccd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('facebook', 0.948005199432373),\n",
              " ('tweet', 0.9403423070907593),\n",
              " ('fb', 0.9342358708381653),\n",
              " ('instagram', 0.9104824066162109),\n",
              " ('chat', 0.8964964747428894),\n",
              " ('hashtag', 0.8885937333106995),\n",
              " ('tweets', 0.8878158330917358),\n",
              " ('tl', 0.8778461217880249),\n",
              " ('link', 0.8778210878372192),\n",
              " ('internet', 0.8753897547721863)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Use the downloaded vectors as usual:\n",
        "glove_vectors.most_similar('twitter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvnW9NgBGwla"
      },
      "source": [
        "# Document/Sentence Embeddings\n",
        "Paragraph, Sentence, and Document embeddings\n",
        "\n",
        "## Doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If7cxdRzGwlj",
        "outputId": "403ffd8d-bff5-4bb2-da5f-321672b60660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Embeddings:\n",
            "[array([-0.02210109,  0.01075956,  0.01045155, -0.00168552,  0.04389304,\n",
            "       -0.01646093, -0.01722671,  0.00359221, -0.03919   ,  0.04840723],\n",
            "      dtype=float32), array([-0.04275137, -0.04523604,  0.00160485, -0.04087964, -0.00095917,\n",
            "        0.01051954,  0.02245842, -0.01437612,  0.04036413, -0.03224698],\n",
            "      dtype=float32), array([ 0.02298321, -0.00912871, -0.03395214, -0.03105471,  0.02194284,\n",
            "       -0.01394829, -0.02887552, -0.04132728,  0.0022589 , -0.03036125],\n",
            "      dtype=float32), array([ 0.04444262, -0.04302356, -0.02289297, -0.03036175, -0.03440027,\n",
            "       -0.02493767, -0.04262125,  0.01890945, -0.04977329,  0.02532519],\n",
            "      dtype=float32), array([ 0.04400432, -0.02729604,  0.0402323 ,  0.03534522, -0.0328272 ,\n",
            "        0.00672655,  0.03224795,  0.0401442 ,  0.00959703,  0.01975554],\n",
            "      dtype=float32)]\n",
            "\n",
            "Shape:\n",
            "(5, 10)\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Define your sentences (example)\n",
        "sentences = [\"this is the first sentence\", \"this is the second sentence\", \"yet another sentence\", \"one more sentence\", \"and the final sentence\"]\n",
        "\n",
        "# Tag the sentences for training\n",
        "tagged_data = [TaggedDocument(words=sentence.split(), tags=[str(i)]) for i, sentence in enumerate(sentences)]\n",
        "\n",
        "# Train the model\n",
        "model = Doc2Vec(tagged_data, vector_size=10, window=2, min_count=1, workers=4)\n",
        "\n",
        "# Get the embeddings for the sentences\n",
        "sentence_vectors = [model.infer_vector(sentence.split()) for sentence in sentences]\n",
        "# The infer_vectors expects the input as a list of words (nltk.word_tokenize())\n",
        "\n",
        "print(\"Sentence Embeddings:\")\n",
        "print(sentence_vectors) #Embeddings of the sentences\n",
        "\n",
        "import numpy as np\n",
        "print(\"\\nShape:\")\n",
        "print(np.array(sentence_vectors).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF1RI8k8Gwlk",
        "outputId": "c542d019-2610-4d59-e604-5f9703980a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02210109  0.01075956  0.01045155 -0.00168552  0.04389304 -0.01646093\n",
            " -0.01722671  0.00359221 -0.03919     0.04840723]\n"
          ]
        }
      ],
      "source": [
        "print(sentence_vectors[0]) #the first embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XesFtYhGwll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce921e9-2d84-4238-bee8-bf7b1a91f354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18947186"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(sentence_vectors[1].reshape(1,-1),sentence_vectors[2].reshape(1,-1))[0][0]\n",
        "#Cosine similarity between embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DKoWDb-Gwln",
        "outputId": "46ad5f45-3629-4c8c-989e-157806038684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.3741152 ,  0.3242597 , -0.03134688, -0.41970065],\n",
              "       [-0.3741152 ,  1.        ,  0.19963288,  0.09588649,  0.08309498],\n",
              "       [ 0.3242597 ,  0.19963288,  0.99999994, -0.3109943 , -0.09789877],\n",
              "       [-0.03134688,  0.09588649, -0.3109943 ,  1.        ,  0.44980752],\n",
              "       [-0.41970065,  0.08309498, -0.09789877,  0.44980752,  0.9999999 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Find the similarity between all the sentences\n",
        "similarity = cosine_similarity(sentence_vectors)\n",
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_8s2ff2Gwlo",
        "outputId": "278ee5c0-1ba3-48ea-bf3e-67a6e68aa1fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence --> this is the first sentence\n",
            "Most Similar Sentence --> yet another sentence\n",
            "Cosine Simialrity: 0.3242597\n"
          ]
        }
      ],
      "source": [
        "#Find the most similar sentence to the first sentence (at index = 0)\n",
        "idx = 0  # The index of the sentence for which you want to find the most similar sentence\n",
        "max = -1 # This will store the cosine_similarity of the most similar document\n",
        "max_idx = -1\n",
        "print(\"Input Sentence -->\", sentences[idx])\n",
        "for i in range(np.array(sentence_vectors).shape[0]):\n",
        "    if i == idx:\n",
        "      continue\n",
        "    sim = cosine_similarity(sentence_vectors[i].reshape(1,-1),\n",
        "                            sentence_vectors[idx].reshape(1,-1))[0][0]\n",
        "    if max < sim:\n",
        "        max = sim\n",
        "        max_idx = i\n",
        "\n",
        "print(\"Most Similar Sentence -->\", sentences[max_idx])\n",
        "print(\"Cosine Simialrity:\", max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZynnc0BGwlp"
      },
      "source": [
        "#### More about Doc2vec here:\n",
        "https://radimrehurek.com/gensim/models/doc2vec.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S58AcfXwj0Wo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}